{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1471fa3",
   "metadata": {},
   "source": [
    "# Experiment 1: Pose MLP - Enhanced Feature Engineering\n",
    "\n",
    "Robust comparison of pose-based models using **30-run aggregated statistics** with config-based training.\n",
    "\n",
    "## Configurations\n",
    "\n",
    "| Config | Features | Description |\n",
    "|--------|----------|-------------|\n",
    "| **A** (Baseline) | 19 | 13 joint angles + 6 distances |\n",
    "| **B** (Specialized) | 37 | Base + 18 specialized discrimination features |\n",
    "\n",
    "**Key Features:**\n",
    "- Enhanced pose features with specialized discrimination for confusion clusters\n",
    "- Temporal sequences (50 timesteps \u00d7 N features)\n",
    "- Subject-wise stratified train/val/test splits (no subject leakage)\n",
    "- 30 runs per configuration with different random seeds\n",
    "- Comprehensive statistical analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "PROJECT_ROOT = Path('..').resolve().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# Force reload modules to pick up latest changes\n",
    "import importlib\n",
    "import src.data.data_loader\n",
    "import src.data.dataset_builder\n",
    "import src.scripts.experiment_1\n",
    "importlib.reload(src.data.data_loader)\n",
    "importlib.reload(src.data.dataset_builder)\n",
    "importlib.reload(src.scripts.experiment_1)\n",
    "\n",
    "from src.data.data_loader import load_pose_enhanced_data\n",
    "from src.scripts.experiment_1 import train_experiment_1_multi_run\n",
    "\n",
    "\n",
    "print(\"\u2705 Modules loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308dced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(src.utils.visualization)\n",
    "\n",
    "from src.utils.visualization import (\n",
    "    plot_confusion_matrix_from_metrics,\n",
    "    plot_per_class_f1_scores,\n",
    "    sort_labels_by_numeric_prefix,\n",
    "    display_multi_run_summary,\n",
    "    plot_multi_run_distributions,\n",
    "    plot_best_worst_comparison,\n",
    "    plot_aggregated_confusion_matrix,\n",
    "    plot_dual_training_history,\n",
    "    compare_multi_run_stats,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\u2705 Visualization functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b78b6b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Configuration Selection\n",
    "\n",
    "Select which configuration to run. Available options:\n",
    "\n",
    "- **`A`** - Baseline: 19 features (13 angles + 6 distances)\n",
    "- **`B`** - Base + Specialized: 37 features (19 + 18 specialized discrimination features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# \ud83d\udd27 CONFIGURATION SELECTION - MODIFY THIS CELL\n",
    "# ============================================================\n",
    "\n",
    "# Select configuration: 'A' or 'B'\n",
    "SELECTED_CONFIG = 'B'\n",
    "\n",
    "# Select view: 'front' or 'side'\n",
    "SELECTED_VIEW = 'side'\n",
    "\n",
    "# ============================================================\n",
    "# Configuration mappings (DO NOT MODIFY)\n",
    "# ============================================================\n",
    "\n",
    "CONFIG_MAP = {\n",
    "    'A': {\n",
    "        'name': 'Baseline',\n",
    "        'feature_type_front': 'all',\n",
    "        'feature_type_side': 'all',\n",
    "        'num_features': 19,\n",
    "        'config_front': 'experiment_1_baseline_front.yaml',\n",
    "        'config_side': 'experiment_1_baseline_side.yaml',\n",
    "        'description': '13 joint angles + 6 distances'\n",
    "    },\n",
    "    'B': {\n",
    "        'name': 'Base + Specialized',\n",
    "        'feature_type_front': 'front_all_extended',\n",
    "        'feature_type_side': 'side_all_extended',\n",
    "        'num_features': 37,\n",
    "        'config_front': 'experiment_1_specialized_front.yaml',\n",
    "        'config_side': 'experiment_1_specialized_side.yaml',\n",
    "        'description': '19 base + 18 specialized discrimination features'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Get selected configuration\n",
    "config_info = CONFIG_MAP[SELECTED_CONFIG]\n",
    "config_file = config_info[f'config_{SELECTED_VIEW}']\n",
    "feature_type = config_info[f'feature_type_{SELECTED_VIEW}']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"\ud83d\udccb SELECTED CONFIGURATION: {SELECTED_CONFIG} - {config_info['name']}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  View: {SELECTED_VIEW.upper()}\")\n",
    "print(f\"  Feature type: {feature_type}\")\n",
    "print(f\"  Number of features: {config_info['num_features']}\")\n",
    "print(f\"  Description: {config_info['description']}\")\n",
    "print(f\"  Config file: {config_file}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222de705",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Loading\n",
    "\n",
    "Load and summarize the enhanced pose feature dataset for the selected view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaea5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to enhanced pose NPZ files\n",
    "npz_paths = {\n",
    "    'front': PROJECT_ROOT / 'datasets' / 'Mediapipe pose estimates' / 'pose_data_front_19_features.npz',\n",
    "    'side': PROJECT_ROOT / 'datasets' / 'Mediapipe pose estimates' / 'pose_data_side_19_features.npz'\n",
    "}\n",
    "\n",
    "# Load data for selected view\n",
    "npz_path = npz_paths[SELECTED_VIEW]\n",
    "\n",
    "dataset, summary = load_pose_enhanced_data(str(npz_path), feature_type=feature_type)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca {SELECTED_VIEW.upper()} VIEW - {config_info['name']} Features:\")\n",
    "print(f\"  Samples: {summary['count']}\")\n",
    "print(f\"  Subjects: {summary['unique_subjects']}\")\n",
    "print(f\"  Classes: {summary['unique_classes']}\")\n",
    "print(f\"  Temporal shape: {summary['temporal_shape']} (timesteps \u00d7 features)\")\n",
    "print(f\"  Flattened to: {summary['temporal_shape'][0] * summary['temporal_shape'][1]} features per sample\")\n",
    "print(f\"\\n  Feature names ({len(summary['feature_names'])}):\")\n",
    "for i, name in enumerate(summary['feature_names'][:10]):\n",
    "    print(f\"    {i+1}. {name}\")\n",
    "if len(summary['feature_names']) > 10:\n",
    "    print(f\"    ... and {len(summary['feature_names']) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c806d13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Multi-Run Training (30 Runs)\n",
    "\n",
    "Execute 30 training runs with different random seeds using the selected configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fac07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with multi-run (30 runs)\n",
    "print(\"=\" * 80)\n",
    "print(f\"MULTI-RUN TRAINING: CONFIG {SELECTED_CONFIG} ({config_info['name']}) - {SELECTED_VIEW.upper()} VIEW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "config_path = PROJECT_ROOT / 'config' / config_file\n",
    "\n",
    "multi_run_results, aggregated_stats = train_experiment_1_multi_run(\n",
    "    npz_path=str(npz_path),\n",
    "    config_path=str(config_path)\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2705 Config {SELECTED_CONFIG} ({SELECTED_VIEW} view) multi-run training complete!\")\n",
    "print(f\"Mean Test Accuracy: {aggregated_stats['test_accuracy']['mean']:.4f} \u00b1 {aggregated_stats['test_accuracy']['std']:.4f}\")\n",
    "print(f\"Mean Test Macro F1: {aggregated_stats['test_macro_f1']['mean']:.4f} \u00b1 {aggregated_stats['test_macro_f1']['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f46795",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Multi-Run Analysis\n",
    "\n",
    "Detailed analysis of 30 runs for the selected configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a180fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary table for runs\n",
    "print(\"=\" * 80)\n",
    "print(f\"CONFIG {SELECTED_CONFIG} ({config_info['name']}) - {SELECTED_VIEW.upper()} VIEW: SUMMARY OF 30 RUNS\")\n",
    "print(\"=\" * 80)\n",
    "summary_df = display_multi_run_summary(multi_run_results, aggregated_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cabf51",
   "metadata": {},
   "source": [
    "### Distribution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c2e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions for runs\n",
    "plot_multi_run_distributions(multi_run_results, aggregated_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d967b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best vs worst run comparison\n",
    "label_names = sorted(multi_run_results[0]['label_to_int'].keys())\n",
    "ordered_labels = sort_labels_by_numeric_prefix(label_names)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"CONFIG {SELECTED_CONFIG}: BEST vs WORST RUN COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "comparison_df = plot_best_worst_comparison(multi_run_results, ordered_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84e2e7b",
   "metadata": {},
   "source": [
    "### Best vs Worst Run Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a21e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aggregated_confusion_matrix(\n",
    "    multi_run_results,\n",
    "    label_names=ordered_labels,\n",
    "    desired_class_order=ordered_labels,\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146af024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best run for detailed analysis\n",
    "best_run = max(multi_run_results, key=lambda x: x['test_metrics']['macro_f1'])\n",
    "\n",
    "print(f\"\ud83c\udfc6 Best Run Performance (Config {SELECTED_CONFIG} - {SELECTED_VIEW}):\")\n",
    "print(f\"   Accuracy: {best_run['test_metrics']['accuracy']:.4f}\")\n",
    "print(f\"   Macro F1: {best_run['test_metrics']['macro_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for best run\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(best_run['history']['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(best_run['history']['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title(f'Config {SELECTED_CONFIG} Best Run: Loss Curves')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(best_run['history']['accuracy'], label='Train Acc', linewidth=2)\n",
    "axes[1].plot(best_run['history']['val_accuracy'], label='Val Acc', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title(f'Config {SELECTED_CONFIG} Best Run: Accuracy Curves')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee92d16f",
   "metadata": {},
   "source": [
    "### Per-Class F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56daab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class F1 scores for best run\n",
    "idx_to_label = {int(k): v for k, v in best_run['int_to_label'].items()}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "plot_per_class_f1_scores(\n",
    "    best_run['test_metrics']['per_class_f1'],\n",
    "    idx_to_label,\n",
    "    desired_class_order=ordered_labels,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title(f'Config {SELECTED_CONFIG} Best Run: Per-Class F1 Scores', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ee321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for best run\n",
    "conf_matrix = np.array(best_run['test_metrics']['confusion_matrix'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "plot_confusion_matrix_from_metrics(\n",
    "    conf_matrix,\n",
    "    current_class_order=label_names,\n",
    "    desired_class_order=ordered_labels,\n",
    "    normalize=True,\n",
    "    title=f'Config {SELECTED_CONFIG} Best Run: Normalized Confusion Matrix'\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edecb8f",
   "metadata": {},
   "source": [
    "# Final summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf388d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(f\"FINAL SUMMARY: CONFIG {SELECTED_CONFIG} ({config_info['name']}) - {SELECTED_VIEW.upper()} VIEW\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nConfiguration Details:\")\n",
    "print(f\"  Feature type: {config_info['feature_type']}\")\n",
    "print(f\"  Number of features: {config_info['num_features']}\")\n",
    "print(f\"  Description: {config_info['description']}\")\n",
    "\n",
    "print(f\"\\nResults (30 runs):\")\n",
    "print(f\"  Test Accuracy: {aggregated_stats['test_accuracy']['mean']:.4f} \u00b1 {aggregated_stats['test_accuracy']['std']:.4f}\")\n",
    "print(f\"  Test Macro F1: {aggregated_stats['test_macro_f1']['mean']:.4f} \u00b1 {aggregated_stats['test_macro_f1']['std']:.4f}\")\n",
    "print(f\"  Accuracy Range: [{aggregated_stats['test_accuracy']['min']:.4f}, {aggregated_stats['test_accuracy']['max']:.4f}]\")\n",
    "print(f\"  F1 Range: [{aggregated_stats['test_macro_f1']['min']:.4f}, {aggregated_stats['test_macro_f1']['max']:.4f}]\")\n",
    "\n",
    "print(f\"\\nBest Run:\")\n",
    "print(f\"  Accuracy: {best_run['test_metrics']['accuracy']:.4f}\")\n",
    "print(f\"  Macro F1: {best_run['test_metrics']['macro_f1']:.4f}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a044f9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## (Optional) Load & Compare Multiple Configurations\n",
    "\n",
    "Run this section after running multiple configurations to compare their results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd95f6d",
   "metadata": {},
   "source": [
    "### Side-View Specialized Features (Config B - Side)\n",
    "\n",
    "The side-view specialized features experiment includes **18 additional features** designed to address confusion patterns specific to the side-view camera angle:\n",
    "\n",
    "**Feature Groups:**\n",
    "1. **Vertical Displacement (4 features)**: Targets Shrugs vs Calf Raises\n",
    "   - `shoulder_elevation_y`, `heel_ground_clearance`, `shoulder_hip_y_ratio`, `ear_shoulder_compression`\n",
    "\n",
    "2. **Overhead Arm Position (4 features)**: Targets Overhead Triceps Extension\n",
    "   - `elbow_above_shoulder`, `wrist_above_elbow`, `upper_arm_vertical_angle_side`, `forearm_vertical_angle_side`\n",
    "\n",
    "3. **Sagittal Arm Trajectory (4 features)**: Targets Curl variants and Pressing movements\n",
    "   - `wrist_forward_of_shoulder`, `elbow_forward_of_hip`, `arm_reach_forward`, `elbow_tuck_side`\n",
    "\n",
    "4. **Hip Hinge Profile (4 features)**: Targets Deadlift/Rows/Kickbacks\n",
    "   - `torso_angle_from_vertical`, `hip_behind_ankle`, `shoulder_forward_of_hip`, `knee_hip_alignment_z`\n",
    "\n",
    "5. **Postural Stability (2 features)**: General body position context\n",
    "   - `stance_width_normalized`, `center_of_mass_y`\n",
    "\n",
    "**Total Features**: 19 base + 18 specialized = **37 features** \u00d7 50 timesteps = 1850 input dimensions\n",
    "\n",
    "**Expected Results**: These features are designed to improve F1 scores for previously underperforming exercises (Shrugs: baseline 0.59, Overhead Triceps Extension: baseline 0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06706383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from saved multi-run folders (after running multiple configs)\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def load_multi_run_stats(results_dir: str) -> dict:\n",
    "    \"\"\"Load aggregated stats from a multi-run results folder.\"\"\"\n",
    "    stats_path = Path(results_dir) / 'aggregated_stats.json'\n",
    "    if stats_path.exists():\n",
    "        with open(stats_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return None\n",
    "\n",
    "# Define result directories for each config and view combination\n",
    "# Update the multi_run folder numbers to match your actual results\n",
    "result_dirs_front = {\n",
    "    'A': PROJECT_ROOT / 'output/exer_recog/exp_01_pose_mlp_baseline/front/multi_run_001',\n",
    "    'B': PROJECT_ROOT / 'output/exer_recog/exp_01_pose_mlp_specialized/front/multi_run_001',\n",
    "}\n",
    "\n",
    "result_dirs_side = {\n",
    "    'A': PROJECT_ROOT / 'output/exer_recog/exp_01_pose_mlp_baseline/side/multi_run_003',\n",
    "    'B': PROJECT_ROOT / 'output/exer_recog/exp_01_pose_mlp_specialized/side/multi_run_001',\n",
    "}\n",
    "\n",
    "# Select appropriate result directories based on current view\n",
    "result_dirs = result_dirs_front if SELECTED_VIEW == 'front' else result_dirs_side\n",
    "\n",
    "# Load stats directly from specified folders\n",
    "all_stats = {}\n",
    "for config_name, multi_run_folder in result_dirs.items():\n",
    "    if multi_run_folder.exists():\n",
    "        stats = load_multi_run_stats(str(multi_run_folder))\n",
    "        if stats:\n",
    "            all_stats[config_name] = stats\n",
    "            print(f\"\u2705 Loaded Config {config_name} ({SELECTED_VIEW}) from {multi_run_folder.name}\")\n",
    "        else:\n",
    "            print(f\"\u26a0\ufe0f  Config {config_name}: No aggregated_stats.json found in {multi_run_folder}\")\n",
    "    else:\n",
    "        print(f\"\u26a0\ufe0f  Config {config_name}: Directory not found - {multi_run_folder}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(all_stats)} configurations for comparison ({SELECTED_VIEW} view)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14797267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all loaded configurations\n",
    "if len(all_stats) >= 2:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"CONFIGURATION COMPARISON - {SELECTED_VIEW.upper()} VIEW\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    comparison_data = []\n",
    "    for config_name, stats in sorted(all_stats.items()):\n",
    "        config_detail = CONFIG_MAP.get(config_name, {'name': 'Unknown', 'num_features': '?'})\n",
    "        comparison_data.append({\n",
    "            'Config': f\"{config_name} ({config_detail['name']})\",\n",
    "            'Features': config_detail['num_features'],\n",
    "            'Accuracy': f\"{stats['test_accuracy']['mean']:.4f} \u00b1 {stats['test_accuracy']['std']:.4f}\",\n",
    "            'Macro F1': f\"{stats['test_macro_f1']['mean']:.4f} \u00b1 {stats['test_macro_f1']['std']:.4f}\",\n",
    "            'Acc Range': f\"[{stats['test_accuracy']['min']:.4f}, {stats['test_accuracy']['max']:.4f}]\",\n",
    "            'F1 Range': f\"[{stats['test_macro_f1']['min']:.4f}, {stats['test_macro_f1']['max']:.4f}]\"\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(\"\\n\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Calculate improvement from Config A to Config B\n",
    "    if 'A' in all_stats and 'B' in all_stats:\n",
    "        acc_improvement = all_stats['B']['test_accuracy']['mean'] - all_stats['A']['test_accuracy']['mean']\n",
    "        f1_improvement = all_stats['B']['test_macro_f1']['mean'] - all_stats['A']['test_macro_f1']['mean']\n",
    "        print(f\"\\n\ud83d\udcc8 Improvement from Baseline (A) to Specialized (B):\")\n",
    "        print(f\"   Accuracy: {acc_improvement:+.4f} ({acc_improvement*100:+.2f}%)\")\n",
    "        print(f\"   Macro F1: {f1_improvement:+.4f} ({f1_improvement*100:+.2f}%)\")\n",
    "    \n",
    "    # Find best config\n",
    "    best_config = max(all_stats.keys(), key=lambda x: all_stats[x]['test_macro_f1']['mean'])\n",
    "    best_f1 = all_stats[best_config]['test_macro_f1']['mean']\n",
    "    print(f\"\\n\ud83c\udfc6 Best Configuration: {best_config} ({CONFIG_MAP[best_config]['name']}) with Macro F1 = {best_f1:.4f}\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  Need at least 2 configurations to compare. Run more configs first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a210ea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## (Optional) Load & Plot Aggregated Confusion Matrix from Saved Results\n",
    "\n",
    "Load a saved multi-run result and plot its aggregated confusion matrix across all 30 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all runs from a saved multi-run folder and compute aggregated confusion matrix\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Specify the multi-run folder to load (update path as needed)\n",
    "MULTI_RUN_PATH = PROJECT_ROOT / 'output/exer_recog/exp_01_pose_mlp_specialized/front/multi_run_010'\n",
    "\n",
    "# Load all runs data\n",
    "all_runs_path = MULTI_RUN_PATH / 'all_runs.json'\n",
    "if all_runs_path.exists():\n",
    "    with open(all_runs_path, 'r') as f:\n",
    "        loaded_runs = json.load(f)\n",
    "    \n",
    "    print(f\"\u2705 Loaded {len(loaded_runs)} runs from {MULTI_RUN_PATH.name}\")\n",
    "    \n",
    "    # Extract label names and create ordered list\n",
    "    first_run = loaded_runs[0]\n",
    "    label_names = sorted(first_run['label_to_int'].keys())\n",
    "    ordered_labels = sort_labels_by_numeric_prefix(label_names)\n",
    "    num_classes = len(label_names)\n",
    "    \n",
    "    # Aggregate confusion matrices\n",
    "    aggregated_cm = np.zeros((num_classes, num_classes), dtype=np.float32)\n",
    "    for run in loaded_runs:\n",
    "        cm = np.array(run['test_metrics']['confusion_matrix'])\n",
    "        aggregated_cm += cm\n",
    "    \n",
    "    # Average across all runs\n",
    "    aggregated_cm /= len(loaded_runs)\n",
    "    \n",
    "    # Plot aggregated confusion matrix\n",
    "    plot_confusion_matrix_from_metrics(\n",
    "        aggregated_cm,\n",
    "        current_class_order=label_names,\n",
    "        desired_class_order=ordered_labels,\n",
    "        normalize=True,\n",
    "        title=f'Aggregated Confusion Matrix (Average of {len(loaded_runs)} runs) - Normalized'\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcca Confusion Matrix Statistics:\")\n",
    "    print(f\"  Total runs averaged: {len(loaded_runs)}\")\n",
    "    print(f\"  Classes: {num_classes}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\u26a0\ufe0f  File not found: {all_runs_path}\")\n",
    "    print(f\"   Make sure to run training first or update MULTI_RUN_PATH\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_global_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
