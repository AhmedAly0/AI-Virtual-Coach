{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6f8f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname('__file__'), '../..')))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✅ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2092cf7",
   "metadata": {},
   "source": [
    "## Load Results from Both Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18915673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Experiment 1 results\n",
    "exp1_path = 'experiments/exer_recog/results/exp_01_baseline/backbone_comparison.csv'\n",
    "exp1_df = pd.read_csv(exp1_path, index_col=0)\n",
    "exp1_df['experiment'] = 'Baseline'\n",
    "\n",
    "# Load Experiment 2 results\n",
    "exp2_path = 'experiments/exer_recog/results/exp_02_progressive/backbone_comparison_exp2.csv'\n",
    "exp2_df = pd.read_csv(exp2_path, index_col=0)\n",
    "exp2_df['experiment'] = 'Progressive'\n",
    "\n",
    "# Combine\n",
    "combined_df = pd.concat([exp1_df, exp2_df])\n",
    "combined_df['backbone'] = combined_df.index\n",
    "\n",
    "print(\"Experiment 1 Summary:\")\n",
    "print(exp1_df[['mean_test_acc', 'std_test_acc']].to_string())\n",
    "print(\"\\nExperiment 2 Summary:\")\n",
    "print(exp2_df[['mean_test_acc', 'std_test_acc']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7444605",
   "metadata": {},
   "source": [
    "## Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison bar plot\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "backbones = exp1_df.index.tolist()\n",
    "x = np.arange(len(backbones))\n",
    "width = 0.35\n",
    "\n",
    "# Plot bars\n",
    "bars1 = ax.bar(x - width/2, exp1_df['mean_test_acc'], width, \n",
    "               yerr=exp1_df['std_test_acc'], label='Baseline', \n",
    "               alpha=0.8, capsize=5)\n",
    "bars2 = ax.bar(x + width/2, exp2_df['mean_test_acc'], width,\n",
    "               yerr=exp2_df['std_test_acc'], label='Progressive',\n",
    "               alpha=0.8, capsize=5)\n",
    "\n",
    "# Formatting\n",
    "ax.set_ylabel('Mean Test Accuracy', fontsize=12)\n",
    "ax.set_title('Baseline vs Progressive Training: Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(backbones, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('experiments/exer_recog/results/cross_experiment_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Comparison plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329fb43",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a12952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare training strategies\n",
    "print(\"=\"*80)\n",
    "print(\"STATISTICAL COMPARISON: Baseline vs Progressive\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for backbone in backbones:\n",
    "    exp1_acc = exp1_df.loc[backbone, 'mean_test_acc']\n",
    "    exp2_acc = exp2_df.loc[backbone, 'mean_test_acc']\n",
    "    \n",
    "    improvement = ((exp2_acc - exp1_acc) / exp1_acc) * 100\n",
    "    \n",
    "    print(f\"\\n{backbone}:\")\n",
    "    print(f\"  Baseline:    {exp1_acc:.4f} ± {exp1_df.loc[backbone, 'std_test_acc']:.4f}\")\n",
    "    print(f\"  Progressive: {exp2_acc:.4f} ± {exp2_df.loc[backbone, 'std_test_acc']:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:+.2f}%\")\n",
    "\n",
    "# Overall statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBaseline Mean:    {exp1_df['mean_test_acc'].mean():.4f} ± {exp1_df['mean_test_acc'].std():.4f}\")\n",
    "print(f\"Progressive Mean: {exp2_df['mean_test_acc'].mean():.4f} ± {exp2_df['mean_test_acc'].std():.4f}\")\n",
    "\n",
    "# Paired t-test\n",
    "t_stat, p_value = stats.ttest_rel(exp1_df['mean_test_acc'], exp2_df['mean_test_acc'])\n",
    "print(f\"\\nPaired t-test: t={t_stat:.4f}, p={p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"✓ Progressive training shows STATISTICALLY SIGNIFICANT improvement (p < 0.05)\")\n",
    "else:\n",
    "    print(\"✗ No statistically significant difference between methods (p ≥ 0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00054df",
   "metadata": {},
   "source": [
    "## Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"BEST MODEL SELECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best model overall\n",
    "best_idx = combined_df['mean_test_acc'].idxmax()\n",
    "best_row = combined_df.loc[best_idx]\n",
    "\n",
    "print(f\"\\nBest Overall Model:\")\n",
    "print(f\"  Backbone:   {best_row['backbone']}\")\n",
    "print(f\"  Strategy:   {best_row['experiment']}\")\n",
    "print(f\"  Accuracy:   {best_row['mean_test_acc']:.4f} ± {best_row['std_test_acc']:.4f}\")\n",
    "\n",
    "# Top 3 models\n",
    "print(\"\\nTop 3 Models:\")\n",
    "top3 = combined_df.nlargest(3, 'mean_test_acc')[['backbone', 'experiment', 'mean_test_acc', 'std_test_acc']]\n",
    "for idx, row in top3.iterrows():\n",
    "    print(f\"  {row['backbone']:20s} ({row['experiment']:12s}): {row['mean_test_acc']:.4f} ± {row['std_test_acc']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe4408e",
   "metadata": {},
   "source": [
    "## Performance vs Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a352458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model parameters\n",
    "from src.utils import get_all_model_parameters\n",
    "\n",
    "backbones_list = [\n",
    "    'efficientnet_b0',\n",
    "    'efficientnet_b2',\n",
    "    'efficientnet_b3',\n",
    "    'resnet50',\n",
    "    'vgg16',\n",
    "    'mobilenet_v2',\n",
    "    'mobilenet_v3_large',\n",
    "]\n",
    "\n",
    "params_df = get_all_model_parameters(backbones_list, img_size=224, num_classes=15)\n",
    "\n",
    "# Merge with results\n",
    "exp1_with_params = exp1_df.merge(params_df, left_index=True, right_on='backbone')\n",
    "exp2_with_params = exp2_df.merge(params_df, left_index=True, right_on='backbone')\n",
    "\n",
    "# Scatter plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.scatter(exp1_with_params['total_params']/1e6, exp1_with_params['mean_test_acc'], \n",
    "           s=100, alpha=0.6, label='Baseline')\n",
    "ax.scatter(exp2_with_params['total_params']/1e6, exp2_with_params['mean_test_acc'],\n",
    "           s=100, alpha=0.6, label='Progressive')\n",
    "\n",
    "# Annotate points\n",
    "for _, row in exp1_with_params.iterrows():\n",
    "    ax.annotate(row['backbone'], (row['total_params']/1e6, row['mean_test_acc']), \n",
    "                fontsize=8, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Model Parameters (millions)', fontsize=12)\n",
    "ax.set_ylabel('Mean Test Accuracy', fontsize=12)\n",
    "ax.set_title('Performance vs Model Complexity', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('experiments/exer_recog/results/performance_vs_complexity.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Performance vs complexity plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48418270",
   "metadata": {},
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary\n",
    "summary_path = 'experiments/exer_recog/results/COMPARISON_SUMMARY.md'\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"# Exercise Recognition: Cross-Experiment Comparison\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Overview\\n\\n\")\n",
    "    f.write(\"This report compares two training strategies across 7 CNN backbones:\\n\")\n",
    "    f.write(\"- **Experiment 1 (Baseline):** 2-phase transfer learning\\n\")\n",
    "    f.write(\"- **Experiment 2 (Progressive):** 3-stage progressive unfreezing with custom heads\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Results Summary\\n\\n\")\n",
    "    f.write(\"### Experiment 1 (Baseline)\\n\\n\")\n",
    "    f.write(exp1_df[['mean_test_acc', 'std_test_acc', 'num_runs']].to_markdown())\n",
    "    f.write(\"\\n\\n### Experiment 2 (Progressive)\\n\\n\")\n",
    "    f.write(exp2_df[['mean_test_acc', 'std_test_acc']].to_markdown())\n",
    "    \n",
    "    f.write(\"\\n\\n## Best Model\\n\\n\")\n",
    "    f.write(f\"**Backbone:** {best_row['backbone']}\\n\\n\")\n",
    "    f.write(f\"**Strategy:** {best_row['experiment']}\\n\\n\")\n",
    "    f.write(f\"**Accuracy:** {best_row['mean_test_acc']:.4f} ± {best_row['std_test_acc']:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Statistical Analysis\\n\\n\")\n",
    "    f.write(f\"**Paired t-test:** t={t_stat:.4f}, p={p_value:.4f}\\n\\n\")\n",
    "    if p_value < 0.05:\n",
    "        f.write(\"✓ Progressive training shows **statistically significant** improvement over baseline.\\n\")\n",
    "    else:\n",
    "        f.write(\"✗ No statistically significant difference between methods.\\n\")\n",
    "    \n",
    "    f.write(\"\\n## Recommendations\\n\\n\")\n",
    "    f.write(\"Based on the analysis:\\n\\n\")\n",
    "    f.write(f\"1. **Best accuracy:** Use {best_row['backbone']} with {best_row['experiment'].lower()} training\\n\")\n",
    "    f.write(\"2. **Best efficiency:** Consider MobileNet variants for deployment\\n\")\n",
    "    f.write(\"3. **Best balance:** EfficientNet models offer strong accuracy with moderate complexity\\n\")\n",
    "\n",
    "print(f\"✓ Summary report saved to: {summary_path}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
